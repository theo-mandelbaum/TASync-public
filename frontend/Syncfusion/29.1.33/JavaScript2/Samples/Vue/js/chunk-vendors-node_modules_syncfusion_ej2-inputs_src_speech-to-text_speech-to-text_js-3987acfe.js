"use strict";
/*
 * ATTENTION: The "eval" devtool has been used (maybe by default in mode: "development").
 * This devtool is neither made for production nor for readable output files.
 * It uses "eval()" calls to create a separate source file in the browser devtools.
 * If you are trying to read the output file, select a different devtool (https://webpack.js.org/configuration/devtool/)
 * or disable the default devtool with "devtool: false".
 * If you are looking for production-ready output files, see mode: "production" (https://webpack.js.org/configuration/mode/).
 */
(self["webpackChunkej2_vue_samples"] = self["webpackChunkej2_vue_samples"] || []).push([["chunk-vendors-node_modules_syncfusion_ej2-inputs_src_speech-to-text_speech-to-text_js-3987acfe"],{

/***/ "./node_modules/@syncfusion/ej2-inputs/src/speech-to-text/speech-to-text.js":
/*!**********************************************************************************!*\
  !*** ./node_modules/@syncfusion/ej2-inputs/src/speech-to-text/speech-to-text.js ***!
  \**********************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   ButtonSettings: () => (/* binding */ ButtonSettings),\n/* harmony export */   SpeechToText: () => (/* binding */ SpeechToText),\n/* harmony export */   SpeechToTextState: () => (/* binding */ SpeechToTextState),\n/* harmony export */   TooltipSettings: () => (/* binding */ TooltipSettings)\n/* harmony export */ });\n/* harmony import */ var _syncfusion_ej2_base__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @syncfusion/ej2-base */ \"./node_modules/@syncfusion/ej2-base/index.js\");\n/* harmony import */ var _syncfusion_ej2_buttons__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! @syncfusion/ej2-buttons */ \"./node_modules/@syncfusion/ej2-buttons/index.js\");\n/* harmony import */ var _syncfusion_ej2_popups__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! @syncfusion/ej2-popups */ \"./node_modules/@syncfusion/ej2-popups/index.js\");\nvar __extends = (undefined && undefined.__extends) || (function () {\n    var extendStatics = function (d, b) {\n        extendStatics = Object.setPrototypeOf ||\n            ({ __proto__: [] } instanceof Array && function (d, b) { d.__proto__ = b; }) ||\n            function (d, b) { for (var p in b) if (b.hasOwnProperty(p)) d[p] = b[p]; };\n        return extendStatics(d, b);\n    };\n    return function (d, b) {\n        extendStatics(d, b);\n        function __() { this.constructor = d; }\n        d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());\n    };\n})();\nvar __decorate = (undefined && undefined.__decorate) || function (decorators, target, key, desc) {\n    var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;\n    if (typeof Reflect === \"object\" && typeof Reflect.decorate === \"function\") r = Reflect.decorate(decorators, target, key, desc);\n    else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;\n    return c > 3 && r && Object.defineProperty(target, key, r), r;\n};\n\n\n\n/**\n * Configuration settings for the toggle button used in the SpeechToText component.\n */\nvar ButtonSettings = /** @class */ (function (_super) {\n    __extends(ButtonSettings, _super);\n    function ButtonSettings() {\n        return _super !== null && _super.apply(this, arguments) || this;\n    }\n    __decorate([\n        (0,_syncfusion_ej2_base__WEBPACK_IMPORTED_MODULE_0__.Property)('')\n    ], ButtonSettings.prototype, \"content\", void 0);\n    __decorate([\n        (0,_syncfusion_ej2_base__WEBPACK_IMPORTED_MODULE_0__.Property)('')\n    ], ButtonSettings.prototype, \"stopContent\", void 0);\n    __decorate([\n        (0,_syncfusion_ej2_base__WEBPACK_IMPORTED_MODULE_0__.Property)('')\n    ], ButtonSettings.prototype, \"iconCss\", void 0);\n    __decorate([\n        (0,_syncfusion_ej2_base__WEBPACK_IMPORTED_MODULE_0__.Property)('')\n    ], ButtonSettings.prototype, \"stopIconCss\", void 0);\n    __decorate([\n        (0,_syncfusion_ej2_base__WEBPACK_IMPORTED_MODULE_0__.Property)('Left')\n    ], ButtonSettings.prototype, \"iconPosition\", void 0);\n    __decorate([\n        (0,_syncfusion_ej2_base__WEBPACK_IMPORTED_MODULE_0__.Property)(false)\n    ], ButtonSettings.prototype, \"isPrimary\", void 0);\n    return ButtonSettings;\n}(_syncfusion_ej2_base__WEBPACK_IMPORTED_MODULE_0__.ChildProperty));\n\n/**\n * Configuration settings for tooltips in the SpeechToText component.\n * This allows customization of the tooltip content and its positioning.\n */\nvar TooltipSettings = /** @class */ (function (_super) {\n    __extends(TooltipSettings, _super);\n    function TooltipSettings() {\n        return _super !== null && _super.apply(this, arguments) || this;\n    }\n    __decorate([\n        (0,_syncfusion_ej2_base__WEBPACK_IMPORTED_MODULE_0__.Property)('Start listening')\n    ], TooltipSettings.prototype, \"content\", void 0);\n    __decorate([\n        (0,_syncfusion_ej2_base__WEBPACK_IMPORTED_MODULE_0__.Property)('Stop listening')\n    ], TooltipSettings.prototype, \"stopContent\", void 0);\n    __decorate([\n        (0,_syncfusion_ej2_base__WEBPACK_IMPORTED_MODULE_0__.Property)('TopCenter')\n    ], TooltipSettings.prototype, \"position\", void 0);\n    return TooltipSettings;\n}(_syncfusion_ej2_base__WEBPACK_IMPORTED_MODULE_0__.ChildProperty));\n\n/**\n * Enum representing the operational states of the SpeechToText component.\n */\nvar SpeechToTextState;\n(function (SpeechToTextState) {\n    /**\n     * Specifies the state where the SpeechToText component is inactive and not processing spoken input.\n     */\n    SpeechToTextState[\"Inactive\"] = \"Inactive\";\n    /**\n     * Specifies the state where the SpeechToText component is actively listening to spoken input.\n     */\n    SpeechToTextState[\"Listening\"] = \"Listening\";\n    /**\n     * Specifies the state where the SpeechToText component has stopped processing spoken input.\n     */\n    SpeechToTextState[\"Stopped\"] = \"Stopped\";\n})(SpeechToTextState || (SpeechToTextState = {}));\n//#endregion\nvar SpeechToText = /** @class */ (function (_super) {\n    __extends(SpeechToText, _super);\n    //#endregion\n    //#region Inherited methods\n    /**\n     * Constructor for creating the component\n     *\n     * @param {SpeechToTextModel} options - Specifies the SpeechToTextModel model.\n     * @param {string | HTMLElement} element - Specifies the element to render as component.\n     * @private\n     */\n    function SpeechToText(options, element) {\n        var _this = _super.call(this, options, element) || this;\n        _this.fullTranscript = '';\n        _this.isClicked = false;\n        _this.isUserInteracted = false;\n        _this.hasStarted = false;\n        return _this;\n    }\n    /**\n     * Initialize the event handler\n     *\n     * @private\n     * @returns {void}\n     */\n    SpeechToText.prototype.preRender = function () {\n        if (!this.element.id) {\n            this.element.id = (0,_syncfusion_ej2_base__WEBPACK_IMPORTED_MODULE_0__.getUniqueID)('e-' + this.getModuleName());\n        }\n    };\n    SpeechToText.prototype.getDirective = function () {\n        return 'EJS-SPEECHTOTEXT';\n    };\n    /**\n     * To get component name.\n     *\n     * @returns {string} - It returns the current module name.\n     * @private\n     */\n    SpeechToText.prototype.getModuleName = function () {\n        return 'speech-to-text';\n    };\n    /**\n     * Get the properties to be maintained in the persisted state.\n     *\n     * @private\n     * @returns {string} - It returns the persisted data.\n     */\n    SpeechToText.prototype.getPersistData = function () {\n        return this.addOnPersist([]);\n    };\n    SpeechToText.prototype.render = function () {\n        this.renderSpeechToText();\n        this.initializeSpeechRecognition();\n        if (!(0,_syncfusion_ej2_base__WEBPACK_IMPORTED_MODULE_0__.isNullOrUndefined)(this.listeningState)) {\n            this.handleStateChange();\n        }\n        this.wireEvents();\n    };\n    //#endregion\n    //#region Private Methods\n    SpeechToText.prototype.initializeLocale = function () {\n        this.l10n = new _syncfusion_ej2_base__WEBPACK_IMPORTED_MODULE_0__.L10n(this.getModuleName(), {\n            abortedError: 'Speech recognition was aborted.',\n            audioCaptureError: 'No microphone detected. Ensure your microphone is connected.',\n            defaultError: 'An unknown error occurred.',\n            networkError: 'Network error occurred. Check your internet connection.',\n            noSpeechError: 'No speech detected. Please speak into the microphone.',\n            notAllowedError: 'Microphone access denied. Allow microphone permissions.',\n            serviceNotAllowedError: 'Speech recognition service is not allowed in this context.',\n            unsupportedBrowserError: 'The browser does not support the SpeechRecognition API.',\n            startAriaLabel: 'Press to start speaking and transcribe your words',\n            stopAriaLabel: 'Press to stop speaking and end transcription',\n            startTooltipText: 'Start listening',\n            stopTooltipText: 'Stop listening'\n        }, this.locale);\n    };\n    SpeechToText.prototype.renderSpeechToText = function () {\n        this.initializeLocale();\n        var iconCss = !(0,_syncfusion_ej2_base__WEBPACK_IMPORTED_MODULE_0__.isNullOrUndefined)(this.buttonSettings.iconCss) && this.buttonSettings.iconCss !== '' ? this.buttonSettings.iconCss : 'e-icons e-listen-icon';\n        this.buttonInst = new _syncfusion_ej2_buttons__WEBPACK_IMPORTED_MODULE_1__.Button({\n            iconCss: iconCss,\n            isPrimary: this.buttonSettings.isPrimary,\n            cssClass: this.updateButtonCssClass(),\n            disabled: this.disabled,\n            content: this.buttonSettings.content,\n            iconPosition: this.buttonSettings.iconPosition,\n            enableRtl: this.enableRtl\n        });\n        this.buttonInst.appendTo(this.element);\n        this.updateTooltip();\n        this.updateCssClass(this.cssClass, '');\n        this.updateAriaLabel();\n        if (!(0,_syncfusion_ej2_base__WEBPACK_IMPORTED_MODULE_0__.isNullOrUndefined)(this.htmlAttributes)) {\n            this.addHtmlAttributes(this.htmlAttributes);\n        }\n    };\n    SpeechToText.prototype.updateAriaLabel = function () {\n        var ariaLabel;\n        if (this.htmlAttributes && this.htmlAttributes['aria-label']) {\n            ariaLabel = this.htmlAttributes['aria-label'];\n        }\n        else {\n            ariaLabel = this.micOn ? this.l10n.getConstant('stopAriaLabel') : this.l10n.getConstant('startAriaLabel');\n        }\n        this.element.setAttribute('aria-label', ariaLabel);\n    };\n    SpeechToText.prototype.updateCssClass = function (newClass, oldClass) {\n        if (oldClass) {\n            (0,_syncfusion_ej2_base__WEBPACK_IMPORTED_MODULE_0__.removeClass)([this.element], oldClass.trim().split(' '));\n        }\n        if (newClass) {\n            (0,_syncfusion_ej2_base__WEBPACK_IMPORTED_MODULE_0__.addClass)([this.element], newClass.trim().split(' '));\n        }\n    };\n    SpeechToText.prototype.updateButtonCssClass = function () {\n        var content = this.isClicked ? this.buttonSettings.stopContent : this.buttonSettings.content;\n        var cssClass;\n        if (content === '') {\n            cssClass = 'e-round';\n        }\n        if (this.micOn) {\n            cssClass += ' e-listening-state';\n        }\n        return cssClass;\n    };\n    SpeechToText.prototype.updateTooltip = function () {\n        if (this.showTooltip) {\n            if (this.tooltipSettings) {\n                if (this.tooltipSettings.content === 'Start listening') {\n                    this.tooltipSettings.content = this.l10n.getConstant('startTooltipText');\n                }\n                if (this.tooltipSettings.stopContent === 'Stop listening') {\n                    this.tooltipSettings.stopContent = this.l10n.getConstant('stopTooltipText');\n                }\n            }\n            this.tooltipInst = new _syncfusion_ej2_popups__WEBPACK_IMPORTED_MODULE_2__.Tooltip({\n                content: this.hasStarted ? this.tooltipSettings.stopContent : this.tooltipSettings.content,\n                position: this.tooltipSettings.position,\n                windowCollision: true,\n                cssClass: this.cssClass ? ('e-speech-to-text-tooltip ' + this.cssClass) : 'e-speech-to-text-tooltip',\n                opensOn: 'Hover',\n                enableRtl: this.enableRtl\n            });\n            this.tooltipInst.appendTo(this.element);\n        }\n        else {\n            if (!(0,_syncfusion_ej2_base__WEBPACK_IMPORTED_MODULE_0__.isNullOrUndefined)(this.tooltipInst)) {\n                this.tooltipInst.destroy();\n                this.tooltipInst = null;\n            }\n        }\n    };\n    SpeechToText.prototype.handleStateChange = function () {\n        if (this.disabled) {\n            return;\n        }\n        if (this.listeningState === SpeechToTextState.Listening) {\n            this.micOn = true;\n            this.startSpeechRecognition();\n        }\n        else if (this.listeningState === SpeechToTextState.Inactive || this.listeningState === SpeechToTextState.Stopped) {\n            if (this.micOn) {\n                this.micOn = false;\n                this.stopSpeechRecognition();\n            }\n            else {\n                var prevOnChange = this.isProtectedOnChange;\n                this.isProtectedOnChange = true;\n                this.listeningState = SpeechToTextState.Inactive;\n                this.isProtectedOnChange = prevOnChange;\n            }\n        }\n    };\n    SpeechToText.prototype.addHtmlAttributes = function (attrs) {\n        if (attrs) {\n            for (var attr in attrs) {\n                if (Object.prototype.hasOwnProperty.call(attrs, attr)) {\n                    this.element.setAttribute(attr, attrs[attr]);\n                }\n            }\n        }\n    };\n    SpeechToText.prototype.removeHtmlAttributes = function (attrs) {\n        if (attrs) {\n            for (var attr in attrs) {\n                if (Object.prototype.hasOwnProperty.call(attrs, attr)) {\n                    this.element.removeAttribute(attr);\n                }\n            }\n        }\n    };\n    SpeechToText.prototype.wireEvents = function () {\n        _syncfusion_ej2_base__WEBPACK_IMPORTED_MODULE_0__.EventHandler.add(this.element, 'click', this.handleButtonClick, this);\n    };\n    SpeechToText.prototype.unWireEvents = function () {\n        _syncfusion_ej2_base__WEBPACK_IMPORTED_MODULE_0__.EventHandler.remove(this.element, 'click', this.handleButtonClick);\n    };\n    SpeechToText.prototype.handleButtonClick = function (event) {\n        this.isUserInteracted = true;\n        this.micOn = !this.micOn;\n        if (this.micOn) {\n            this.startSpeechRecognition(event);\n        }\n        else {\n            this.stopSpeechRecognition(event);\n        }\n    };\n    SpeechToText.prototype.triggerUnSupportedError = function () {\n        var eventArgs = {\n            error: 'unsupported-browser',\n            errorMessage: this.l10n.getConstant('unsupportedBrowserError')\n        };\n        this.trigger('onError', eventArgs);\n    };\n    SpeechToText.prototype.initializeSpeechRecognition = function () {\n        var _this = this;\n        var windowInst = window;\n        var SpeechRecognition = windowInst.SpeechRecognition || windowInst.webkitSpeechRecognition;\n        if (!SpeechRecognition) {\n            this.triggerUnSupportedError();\n            return;\n        }\n        this.recognition = new SpeechRecognition();\n        this.recognition.continuous = true;\n        this.recognition.lang = this.lang;\n        this.recognition.interimResults = this.allowInterimResults;\n        this.recognition.onstart = function (event) {\n            var prevOnChange = _this.isProtectedOnChange;\n            _this.isProtectedOnChange = true;\n            _this.transcript = _this.fullTranscript = '';\n            _this.isProtectedOnChange = prevOnChange;\n            var eventArgs = {\n                cancel: false,\n                listeningState: SpeechToTextState.Listening,\n                event: event,\n                isInteracted: _this.isUserInteracted\n            };\n            _this.trigger('onStart', eventArgs, function () {\n                if (!eventArgs.cancel) {\n                    _this.handleStartRecognition();\n                }\n                else {\n                    _this.recognition.abort();\n                    _this.micOn = false;\n                }\n            });\n        };\n        this.recognition.onend = function (event) {\n            if (_this.hasStarted) {\n                _this.micOn = false;\n                _this.handleStopRecognition(event);\n            }\n        };\n        this.recognition.onerror = function (event) {\n            var errorMessage = '';\n            switch (event.error) {\n                case 'not-allowed':\n                    errorMessage = _this.l10n.getConstant('notAllowedError');\n                    break;\n                case 'audio-capture':\n                    errorMessage = _this.l10n.getConstant('audioCaptureError');\n                    break;\n                case 'network':\n                    errorMessage = _this.l10n.getConstant('networkError');\n                    break;\n                case 'no-speech':\n                    errorMessage = _this.l10n.getConstant('noSpeechError');\n                    break;\n                case 'aborted':\n                    errorMessage = _this.l10n.getConstant('abortedError');\n                    break;\n                case 'service-not-allowed':\n                    errorMessage = _this.l10n.getConstant('serviceNotAllowedError');\n                    break;\n                default:\n                    errorMessage = _this.l10n.getConstant('defaultError');\n            }\n            var eventArgs = {\n                event: event,\n                error: event.error,\n                errorMessage: errorMessage\n            };\n            _this.trigger('onError', eventArgs);\n            _this.isUserInteracted = false;\n        };\n        this.recognition.onresult = function (event) {\n            var result = event.results[event.resultIndex];\n            var interimTranscript = '';\n            var prevOnChange = _this.isProtectedOnChange;\n            _this.isProtectedOnChange = true;\n            if (result.isFinal) {\n                _this.fullTranscript += result[0].transcript;\n                _this.transcript = _this.fullTranscript;\n            }\n            else {\n                interimTranscript += result[0].transcript;\n                _this.transcript = _this.fullTranscript + interimTranscript;\n            }\n            var eventArgs = {\n                event: event,\n                transcript: _this.transcript,\n                isInterimResult: !result.isFinal\n            };\n            _this.trigger('transcriptChanged', eventArgs, function () {\n                if (eventArgs.transcript !== _this.transcript) {\n                    var prevOnChange_1 = _this.isProtectedOnChange;\n                    _this.isProtectedOnChange = true;\n                    _this.transcript = _this.fullTranscript = eventArgs.transcript;\n                    _this.isProtectedOnChange = prevOnChange_1;\n                }\n            });\n            _this.isProtectedOnChange = prevOnChange;\n        };\n    };\n    SpeechToText.prototype.handleStartRecognition = function () {\n        var prevOnChange = this.isProtectedOnChange;\n        this.isProtectedOnChange = true;\n        this.hasStarted = true;\n        this.listeningState = SpeechToTextState.Listening;\n        if (!(0,_syncfusion_ej2_base__WEBPACK_IMPORTED_MODULE_0__.isNullOrUndefined)(this.tooltipInst)) {\n            this.tooltipInst.content = this.tooltipSettings.stopContent;\n        }\n        this.updateAriaLabel();\n        this.isClicked = true;\n        this.buttonInst.cssClass = this.updateButtonCssClass();\n        this.buttonInst.content = this.buttonSettings.stopContent;\n        var iconCss = !(0,_syncfusion_ej2_base__WEBPACK_IMPORTED_MODULE_0__.isNullOrUndefined)(this.buttonSettings.stopIconCss) && this.buttonSettings.stopIconCss !== '' ? this.buttonSettings.stopIconCss : 'e-icons e-listen-stop';\n        this.buttonInst.iconCss = iconCss;\n        this.isProtectedOnChange = prevOnChange;\n    };\n    SpeechToText.prototype.triggerUnSupportedStart = function (event) {\n        var _this = this;\n        var prevOnChange = this.isProtectedOnChange;\n        this.isProtectedOnChange = true;\n        this.transcript = '';\n        this.isProtectedOnChange = prevOnChange;\n        var eventArgs = {\n            cancel: false,\n            listeningState: SpeechToTextState.Listening,\n            event: event,\n            isInteracted: this.isUserInteracted\n        };\n        this.trigger('onStart', eventArgs, function () {\n            if (!eventArgs.cancel) {\n                _this.handleStartRecognition();\n            }\n        });\n    };\n    SpeechToText.prototype.startSpeechRecognition = function (event) {\n        if (this.hasStarted) {\n            return;\n        }\n        if (this.recognition) {\n            this.recognition.start();\n        }\n        else {\n            this.triggerUnSupportedStart(event);\n        }\n    };\n    SpeechToText.prototype.stopSpeechRecognition = function (event) {\n        if (this.recognition) {\n            this.recognition.stop();\n        }\n        else {\n            this.handleStopRecognition(event);\n        }\n    };\n    SpeechToText.prototype.handleStopRecognition = function (event) {\n        if (!this.hasStarted) {\n            return;\n        } // Ensure onStop is only processed if needed\n        var prevOnChange = this.isProtectedOnChange;\n        this.isProtectedOnChange = true;\n        this.listeningState = SpeechToTextState.Stopped;\n        if (!(0,_syncfusion_ej2_base__WEBPACK_IMPORTED_MODULE_0__.isNullOrUndefined)(this.tooltipInst)) {\n            this.tooltipInst.content = this.tooltipSettings.content;\n        }\n        this.updateAriaLabel();\n        this.isClicked = false;\n        this.buttonInst.cssClass = this.updateButtonCssClass();\n        this.buttonInst.content = this.buttonSettings.content;\n        var eventArgs = {\n            listeningState: SpeechToTextState.Stopped,\n            event: event,\n            isInteracted: this.isUserInteracted\n        };\n        this.trigger('onStop', eventArgs);\n        this.listeningState = SpeechToTextState.Inactive;\n        var iconCss = !(0,_syncfusion_ej2_base__WEBPACK_IMPORTED_MODULE_0__.isNullOrUndefined)(this.buttonSettings.iconCss) && this.buttonSettings.iconCss !== '' ? this.buttonSettings.iconCss : 'e-icons e-listen-icon';\n        this.buttonInst.iconCss = iconCss;\n        this.hasStarted = false;\n        this.isProtectedOnChange = prevOnChange;\n    };\n    SpeechToText.prototype.buttonSettingsChanges = function (oldModel, newModel) {\n        if (oldModel.content !== newModel.content || oldModel.stopContent !== newModel.stopContent) {\n            this.buttonInst.content = this.hasStarted ? this.buttonSettings.stopContent : this.buttonSettings.content;\n            this.buttonInst.cssClass = this.updateButtonCssClass();\n        }\n        if (oldModel.iconCss !== newModel.iconCss || oldModel.stopIconCss !== newModel.stopIconCss) {\n            var iconCss = !(0,_syncfusion_ej2_base__WEBPACK_IMPORTED_MODULE_0__.isNullOrUndefined)(this.buttonSettings.iconCss) && this.buttonSettings.iconCss !== '' ? this.buttonSettings.iconCss : 'e-icons e-listen-icon';\n            var stopIconCss = !(0,_syncfusion_ej2_base__WEBPACK_IMPORTED_MODULE_0__.isNullOrUndefined)(this.buttonSettings.stopIconCss) && this.buttonSettings.stopIconCss !== '' ? this.buttonSettings.stopIconCss : 'e-icons e-listen-stop';\n            this.buttonInst.iconCss = this.hasStarted ? stopIconCss : iconCss;\n        }\n        if (oldModel.iconPosition !== newModel.iconPosition) {\n            this.buttonInst.iconPosition = this.buttonSettings.iconPosition;\n        }\n        if (oldModel.isPrimary !== newModel.isPrimary) {\n            this.buttonInst.isPrimary = this.buttonSettings.isPrimary;\n        }\n    };\n    SpeechToText.prototype.destroyAndNullify = function (obj) {\n        if (obj) {\n            obj.destroy();\n            obj = null;\n        }\n    };\n    //#endregion\n    //#region Public Methods\n    /**\n     * Destroy the SpeechToText.\n     *\n     * @returns {void}\n     */\n    SpeechToText.prototype.destroy = function () {\n        _super.prototype.destroy.call(this);\n        this.unWireEvents();\n        this.destroyAndNullify(this.buttonInst);\n        this.destroyAndNullify(this.tooltipInst);\n        this.recognition = null;\n        this.micOn = null;\n        this.htmlAttributes = this.tooltipSettings = this.buttonSettings = null;\n        this.element.classList.remove('e-rtl');\n    };\n    /**\n     * Begins the audio capture process by listening to the user's microphone input.\n     * This method initiates the speech-to-text process and continuously updates the `transcript` property with interim and final recognition results.\n     *\n     * @returns {void} No return value.\n     */\n    SpeechToText.prototype.startListening = function () {\n        if (!this.disabled && !this.isClicked) {\n            this.isUserInteracted = false;\n            this.micOn = true;\n            this.startSpeechRecognition();\n        }\n    };\n    /**\n     * Stops the audio capture process and finalizes the speech recognition.\n     * This method ends the ongoing speech-to-text operation and completes the recognition process, storing the final transcription.\n     * It is typically called to stop listening when the user is finished speaking.\n     *\n     * @returns {void} No return value.\n     */\n    SpeechToText.prototype.stopListening = function () {\n        if (!this.disabled && this.isClicked) {\n            this.isUserInteracted = false;\n            this.micOn = false;\n            this.stopSpeechRecognition();\n        }\n    };\n    /**\n     * Called if any of the property value is changed.\n     *\n     * @param  {SpeechToTextModel} newProp - Specifies new properties\n     * @param  {SpeechToTextModel} oldProp - Specifies old properties\n     * @returns {void}\n     * @private\n     */\n    SpeechToText.prototype.onPropertyChanged = function (newProp, oldProp) {\n        for (var _i = 0, _a = Object.keys(newProp); _i < _a.length; _i++) {\n            var prop = _a[_i];\n            switch (prop) {\n                case 'lang':\n                    if (this.recognition) {\n                        this.recognition.lang = this.lang;\n                    }\n                    break;\n                case 'allowInterimResults':\n                    if (this.recognition) {\n                        this.recognition.interimResults = this.allowInterimResults;\n                    }\n                    break;\n                case 'buttonSettings':\n                    this.buttonSettingsChanges(oldProp.buttonSettings, newProp.buttonSettings);\n                    break;\n                case 'cssClass':\n                    this.updateCssClass(newProp.cssClass, oldProp.cssClass);\n                    break;\n                case 'disabled':\n                    this.buttonInst.disabled = this.disabled;\n                    this.handleStateChange();\n                    break;\n                case 'htmlAttributes':\n                    this.removeHtmlAttributes(oldProp.htmlAttributes);\n                    this.addHtmlAttributes(newProp.htmlAttributes);\n                    break;\n                case 'listeningState':\n                    this.handleStateChange();\n                    break;\n                case 'tooltipSettings':\n                case 'showTooltip':\n                    this.updateTooltip();\n                    break;\n                case 'transcript':\n                    this.transcript = this.fullTranscript = newProp.transcript;\n                    break;\n                case 'enableRtl':\n                    this.buttonInst.enableRtl = this.tooltipInst.enableRtl = this.enableRtl;\n                    break;\n                case 'locale':\n                    this.l10n.setLocale(this.locale);\n                    this.updateAriaLabel();\n                    this.updateTooltip();\n                    break;\n            }\n        }\n    };\n    __decorate([\n        (0,_syncfusion_ej2_base__WEBPACK_IMPORTED_MODULE_0__.Property)('')\n    ], SpeechToText.prototype, \"transcript\", void 0);\n    __decorate([\n        (0,_syncfusion_ej2_base__WEBPACK_IMPORTED_MODULE_0__.Property)('')\n    ], SpeechToText.prototype, \"lang\", void 0);\n    __decorate([\n        (0,_syncfusion_ej2_base__WEBPACK_IMPORTED_MODULE_0__.Property)(true)\n    ], SpeechToText.prototype, \"allowInterimResults\", void 0);\n    __decorate([\n        (0,_syncfusion_ej2_base__WEBPACK_IMPORTED_MODULE_0__.Property)(true)\n    ], SpeechToText.prototype, \"showTooltip\", void 0);\n    __decorate([\n        (0,_syncfusion_ej2_base__WEBPACK_IMPORTED_MODULE_0__.Property)('Inactive')\n    ], SpeechToText.prototype, \"listeningState\", void 0);\n    __decorate([\n        (0,_syncfusion_ej2_base__WEBPACK_IMPORTED_MODULE_0__.Complex)({}, ButtonSettings)\n    ], SpeechToText.prototype, \"buttonSettings\", void 0);\n    __decorate([\n        (0,_syncfusion_ej2_base__WEBPACK_IMPORTED_MODULE_0__.Complex)({}, TooltipSettings)\n    ], SpeechToText.prototype, \"tooltipSettings\", void 0);\n    __decorate([\n        (0,_syncfusion_ej2_base__WEBPACK_IMPORTED_MODULE_0__.Property)(false)\n    ], SpeechToText.prototype, \"disabled\", void 0);\n    __decorate([\n        (0,_syncfusion_ej2_base__WEBPACK_IMPORTED_MODULE_0__.Property)('')\n    ], SpeechToText.prototype, \"cssClass\", void 0);\n    __decorate([\n        (0,_syncfusion_ej2_base__WEBPACK_IMPORTED_MODULE_0__.Property)({})\n    ], SpeechToText.prototype, \"htmlAttributes\", void 0);\n    __decorate([\n        (0,_syncfusion_ej2_base__WEBPACK_IMPORTED_MODULE_0__.Event)()\n    ], SpeechToText.prototype, \"created\", void 0);\n    __decorate([\n        (0,_syncfusion_ej2_base__WEBPACK_IMPORTED_MODULE_0__.Event)()\n    ], SpeechToText.prototype, \"onStart\", void 0);\n    __decorate([\n        (0,_syncfusion_ej2_base__WEBPACK_IMPORTED_MODULE_0__.Event)()\n    ], SpeechToText.prototype, \"onStop\", void 0);\n    __decorate([\n        (0,_syncfusion_ej2_base__WEBPACK_IMPORTED_MODULE_0__.Event)()\n    ], SpeechToText.prototype, \"onError\", void 0);\n    __decorate([\n        (0,_syncfusion_ej2_base__WEBPACK_IMPORTED_MODULE_0__.Event)()\n    ], SpeechToText.prototype, \"transcriptChanged\", void 0);\n    SpeechToText = __decorate([\n        _syncfusion_ej2_base__WEBPACK_IMPORTED_MODULE_0__.NotifyPropertyChanges\n    ], SpeechToText);\n    return SpeechToText;\n}(_syncfusion_ej2_base__WEBPACK_IMPORTED_MODULE_0__.Component));\n\n\n\n//# sourceURL=webpack://ej2-vue-samples/./node_modules/@syncfusion/ej2-inputs/src/speech-to-text/speech-to-text.js?");

/***/ })

}]);