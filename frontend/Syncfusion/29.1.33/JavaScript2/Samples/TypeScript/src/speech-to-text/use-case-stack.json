{"index.html":"<html><head><link href=\"https://cdn.syncfusion.com/ej2/28.1.33/{{theme}}.css\" rel=\"stylesheet\">\n\n    <link href=\"https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css\" rel=\"stylesheet\">\n\n    <style>\n            body{\n                touch-action:none;\n            }\n            .control-section{\n                margin-top:100px;\n            }\n        </style></head><body><div class=\"stackblitz-container {{theme}}\">\n<div class=\"control-section\">\n    <div class=\"usecase-speechToText-section e-message\">\n        <div class=\"stt-container\">\n            <!-- Microphone button for Speech-to-Text -->\n            <button id=\"speechToText\"></button>\n            <span class=\"speech-recognition-status\">Click the mic button to start speaking...</span>\n        </div>\n        <div class=\"transcript-container\">\n            <!-- Transcription output -->\n            <div id=\"transcript-content\"></div>\n        </div>\n    </div>\n</div>\n\n<script id=\"emptyChatTemplate\" type=\"text/x-jsrender\">\n    <div class=\"empty-chat\">\n        <span class=\"e-icons e-multiple-comment\"></span>\n        No transcript available. Start speaking to generate a transcript.\n    </div>\n</script>\n\n<script id=\"typingIndicatorTemplate\" type=\"text/x-jsrender\">\n    <div class=\"e-typing-indicator \">\n        <span class=\"e-user-text\">Transcripting</span> \n        <div class=\"e-indicator-wrapper\">\n            <span class=\"e-indicator\"></span>\n            <span class=\"e-indicator\">\n            </span><span class=\"e-indicator\">\n            </span>\n        </div>\n    </div>\n</script>\n\n\n\n\n\n<style>\n    .usecase-speechToText-section,\n    .e-bigger .usecase-speechToText-section {\n        width: 90%;\n        height: 55vh;\n        margin: 0 auto;\n        padding: 0;\n        display: flex;\n    }\n\n    .usecase-speechToText-section #transcript-content {\n        border: none;\n        border-top-right-radius: 8px;\n        border-bottom-right-radius: 8px;\n    }\n\n    .usecase-speechToText-section .stt-container {\n        width: 70%;\n        height: 100%;\n        display: flex;\n        flex-direction: column;\n        align-items: center;\n        justify-content: center;\n        gap: 40px;\n    }\n\n    .usecase-speechToText-section .e-speech-to-text.usecase-stt-btn {\n        width: 100px;\n        height: 100px;\n        position: relative;\n    }\n\n    .usecase-speechToText-section .usecase-stt-btn .e-btn-icon,\n    .e-bigger .usecase-speechToText-section .usecase-stt-btn .e-btn-icon {\n        font-size: 50px;\n    }\n\n    .usecase-speechToText-section .transcript-container {\n        width: 30%;\n        height: 100%;\n    }\n\n    /* Create wave effect using pseudo-elements */\n    .usecase-stt-btn::before,\n    .usecase-stt-btn::after {\n        content: \"\";\n        position: absolute;\n        top: 50%;\n        left: 50%;\n        width: 100%;\n        height: 100%;\n        border-radius: 50%;\n        background: #9b9b9b;\n        transform: translate(-50%, -50%) scale(1);\n        opacity: 0;\n        pointer-events: none;\n    }\n\n    .usecase-speechToText-section .stt-listening-state::before {\n        animation: stt-wave-ring 1.5s infinite ease-out;\n    }\n\n    .usecase-speechToText-section .stt-listening-state::after {\n        animation: stt-wave-ring 1.5s 0.75s infinite ease-out; /* Slight delay for second wave */\n    }\n\n    @keyframes stt-wave-ring {\n        0% {\n            transform: translate(-50%, -50%) scale(1);\n            opacity: 0.8;\n        }\n        100% {\n            transform: translate(-50%, -50%) scale(2);\n            opacity: 0;\n        }\n    }\n\n    .usecase-speechToText-section .empty-chat {\n        width: 90%;\n        display: flex;\n        justify-content: center;\n        align-items: center;\n        font-size: 15px;\n        flex-direction: column;\n        gap: 10px;\n        text-align: center;\n        margin: auto;\n    }\n\n    .usecase-speechToText-section .empty-chat .e-multiple-comment {\n        font-size: 50px;\n    }\n\n    .usecase-speechToText-section #transcript-content.e-chat-ui .e-message-group {\n        max-width: 95%;\n    }\n\n    @media only screen and (max-width: 850px) {\n        .usecase-speechToText-section, \n        .e-bigger .usecase-speechToText-section {\n            flex-direction: column;\n            height: 70vh;\n        }\n        .usecase-speechToText-section .transcript-container {\n            width: 100%;\n            height: 70vh;\n            overflow: scroll;\n        }\n        .usecase-speechToText-section .stt-container {\n            width: 100%;\n            height: 55%;\n        }\n    }\n</style>\n</div></body></html>","package.json":"{\n  \"@syncfusion/ej2-base\": \"*\",\n  \"@syncfusion/ej2-buttons\": \"*\",\n  \"@syncfusion/ej2-popups\": \"*\",\n  \"@syncfusion/ej2-splitbuttons\": \"*\",\n  \"markdown-spellcheck\": \"^1.3.1\",\n  \"@syncfusion/ej2-inputs\": \"*\",\n  \"@syncfusion/ej2-navigations\": \"*\",\n  \"@syncfusion/ej2-notifications\": \"*\",\n  \"@syncfusion/ej2-interactive-chat\": \"*\",\n  \"@types/crossroads\": \"0.0.28\",\n  \"@types/signals\": \"0.0.16\",\n  \"@types/moment-timezone\": \"^0.5.3\",\n  \"@types/hasher\": \"0.0.27\",\n  \"fuse.js\": \"^3.2.0\",\n  \"marked\": \"5.1.2\",\n  \"codemirror\": \"^5.37.0\",\n  \"crossroads\": \"^0.12.2\",\n  \"@types/marked\": \"5.0.1\",\n  \"@types/codemirror\": \"0.0.56\",\n  \"@types/es6-promise\": \"0.0.28\",\n  \"hasher\": \"^1.2.0\",\n  \"moment-timezone\": \"^0.5.14\"\n}","index.ts":"{{ripple}}import { SpeechToText } from '@syncfusion/ej2-inputs';\n\nimport { ChatUI } from '@syncfusion/ej2-interactive-chat';\n\n    \n\n    // Initialize Speech-to-Text component\n    var speechToTextObj: SpeechToText = new SpeechToText({\n        buttonSettings: {\n            stopIconCss: 'e-icons e-listen-icon'\n        },\n        transcriptChanged: onTranscriptChange,\n        onStart: onListeningStart,\n        onStop: onListeningStop,\n        onError: onErrorHandler,\n        cssClass: 'usecase-stt-btn'\n    });\n    speechToTextObj.appendTo('#speechToText');\n\n    // Initialize Chat UI component\n    var user = { id: 'testing-user', user: 'Testing User' };\n    var msgIdx = -1;\n    var isIndicatorVisible = false;\n\n    var chatUIObj: ChatUI = new ChatUI({\n        showHeader: false,\n        showFooter: false,\n        timeStampFormat: \"MMM d, h:mm a\",\n        autoScrollToBottom: true,\n        emptyChatTemplate: '#emptyChatTemplate',\n        typingUsersTemplate: '#typingIndicatorTemplate'\n    });\n    chatUIObj.appendTo('#transcript-content');\n\n    function onTranscriptChange(args: any) {\n        var existingMsg = chatUIObj.messages[msgIdx];\n        if (existingMsg) {\n            chatUIObj.updateMessage({ text: args.transcript }, existingMsg.id);\n            chatUIObj.scrollToBottom();\n        } else {\n            var newMsg = { id: 'msg-' + (msgIdx + 1), text: args.transcript, author: user };\n            chatUIObj.addMessage(newMsg);\n        }\n\n        // Show typing indicator only if itâ€™s not visible\n        if (!isIndicatorVisible) {\n            chatUIObj.typingUsers = [user];\n            isIndicatorVisible = true;\n        }\n\n        // Final transcript\n        if (!args.isInterimResult) {\n            msgIdx++;\n            speechToTextObj.transcript = '';\n            chatUIObj.typingUsers = [];\n            isIndicatorVisible = false;\n        }\n    }\n\n    // Event handler for listening start\n    function onListeningStart() {\n        msgIdx = chatUIObj.messages.length;\n        this.element.classList.add('stt-listening-state');\n        updateStatus('Listening... Speak now...');\n    }\n\n    // Event handler for listening stop\n    function onListeningStop(args: any) {\n        this.element.classList.remove('stt-listening-state');\n        chatUIObj.typingUsers = [];\n        if (args.isInteracted)\n            updateStatus('Click the mic button to start speaking...');\n    }\n\n    // Event handler for errors\n    function onErrorHandler(args: any) {\n        updateStatus(args.errorMessage);\n        if (args.error === 'unsupported-browser') {\n            speechToTextObj.disabled = true;\n        }\n    }\n\n    // Function to updates the speech recognition status message\n    function updateStatus(status: any) {\n        (document.querySelector('.speech-recognition-status') as HTMLElement).innerText = status;\n    }\n\n"}